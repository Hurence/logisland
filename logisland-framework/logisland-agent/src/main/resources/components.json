[
{"name":"ApplyRegexp","description":"This processor is used to create a new set of fields from one field (using regexp).","component":"com.hurence.logisland.processor.ApplyRegexp","type":"processor","tags":["parser","regex","log","record"],"properties":[{"name":"conflict.resolution.policy","isRequired":false,"description":"What to do when a field with the same name already exists ?","overwrite existing field":"if field already exist","keep only old field":"keep only old field","defaultValue":"keep_only_old_field","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}],"dynamicProperties":[{"name":"alternative regex & mapping","value":"another regex that could match","description":"This processor is used to create a new set of fields from one field (using regexp).","isExpressionLanguageSupported":true}]},
{"name":"BulkAddElasticsearch","description":"Indexes the content of a Record in Elasticsearch using elasticsearch's bulk processor","component":"com.hurence.logisland.processor.elasticsearch.BulkAddElasticsearch","type":"processor","tags":["elasticsearch"],"properties":[{"name":"elasticsearch.client.service","isRequired":true,"description":"The instance of the Controller Service to use for accessing Elasticsearch.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"default.index","isRequired":true,"description":"The name of the index to insert into","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"default.type","isRequired":true,"description":"The type of this document (used by Elasticsearch for indexing and searching)","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"timebased.index","isRequired":true,"description":"do we add a date suffix","No date":"no date added to default index","Today's date":"today's date added to default index","yesterday's date":"yesterday's date added to default index","defaultValue":"no","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.index.field","isRequired":false,"description":"the name of the event field containing es index name => will override index value if set","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.type.field","isRequired":false,"description":"the name of the event field containing es doc type => will override type value if set","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"ConsolidateSession","description":"The ConsolidateSession processor is the Logisland entry point to get and process events from the Web Analytics.As an example here is an incoming event from the Web Analytics:\n\n\"fields\": [{ \"name\": \"timestamp\",              \"type\": \"long\" },{ \"name\": \"remoteHost\",             \"type\": \"string\"},{ \"name\": \"record_type\",            \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"record_id\",              \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"location\",               \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"hitType\",                \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"eventCategory\",          \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"eventAction\",            \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"eventLabel\",             \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"localPath\",              \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"q\",                      \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"n\",                      \"type\": [\"null\", \"int\"],    \"default\": null },{ \"name\": \"referer\",                \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"viewportPixelWidth\",     \"type\": [\"null\", \"int\"],    \"default\": null },{ \"name\": \"viewportPixelHeight\",    \"type\": [\"null\", \"int\"],    \"default\": null },{ \"name\": \"screenPixelWidth\",       \"type\": [\"null\", \"int\"],    \"default\": null },{ \"name\": \"screenPixelHeight\",      \"type\": [\"null\", \"int\"],    \"default\": null },{ \"name\": \"partyId\",                \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"sessionId\",              \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"pageViewId\",             \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"is_newSession\",          \"type\": [\"null\", \"boolean\"],\"default\": null },{ \"name\": \"userAgentString\",        \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"pageType\",               \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"UserId\",                 \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"B2Bunit\",                \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"pointOfService\",         \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"companyID\",              \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"GroupCode\",              \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"userRoles\",              \"type\": [\"null\", \"string\"], \"default\": null },{ \"name\": \"is_PunchOut\",            \"type\": [\"null\", \"string\"], \"default\": null }]The ConsolidateSession processor groups the records by sessions and compute the duration between now and the last received event. If the distance from the last event is beyond a given threshold (by default 30mn), then the session is considered closed.The ConsolidateSession is building an aggregated session object for each active session.This aggregated object includes: - The actual session duration. - A boolean representing wether the session is considered active or closed.   Note: it is possible to ressurect a session if for instance an event arrives after a session has been marked closed. - User related infos: userId, B2Bunit code, groupCode, userRoles, companyId - First visited page: URL - Last visited page: URL The properties to configure the processor are: - sessionid.field:          Property name containing the session identifier (default: sessionId). - timestamp.field:          Property name containing the timestamp of the event (default: timestamp). - session.timeout:          Timeframe of inactivity (in seconds) after which a session is considered closed (default: 30mn). - visitedpage.field:        Property name containing the page visited by the customer (default: location). - fields.to.return:         List of fields to return in the aggregated object. (default: N/A)","component":"com.hurence.logisland.processor.consolidateSession.ConsolidateSession","type":"processor","tags":["analytics","web","session"],"properties":[{"name":"debug","isRequired":false,"description":"Enable debug. If enabled, the original JSON string is embedded in the record_value field of the record.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"session.timeout","isRequired":false,"description":"session timeout in sec","defaultValue":"1800","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sessionid.field","isRequired":false,"description":"the name of the field containing the session id => will override default value if set","defaultValue":"sessionId","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"timestamp.field","isRequired":false,"description":"the name of the field containing the timestamp => will override default value if set","defaultValue":"h2kTimestamp","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"visitedpage.field","isRequired":false,"description":"the name of the field containing the visited page => will override default value if set","defaultValue":"location","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"userid.field","isRequired":false,"description":"the name of the field containing the userId => will override default value if set","defaultValue":"userId","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"fields.to.return","isRequired":false,"description":"the list of fields to return","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"firstVisitedPage.out.field","isRequired":false,"description":"the name of the field containing the first visited page => will override default value if set","defaultValue":"firstVisitedPage","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"lastVisitedPage.out.field","isRequired":false,"description":"the name of the field containing the last visited page => will override default value if set","defaultValue":"lastVisitedPage","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"isSessionActive.out.field","isRequired":false,"description":"the name of the field stating whether the session is active or not => will override default value if set","defaultValue":"is_sessionActive","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sessionDuration.out.field","isRequired":false,"description":"the name of the field containing the session duration => will override default value if set","defaultValue":"sessionDuration","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"eventsCounter.out.field","isRequired":false,"description":"the name of the field containing the session duration => will override default value if set","defaultValue":"eventsCounter","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"firstEventDateTime.out.field","isRequired":false,"description":"the name of the field containing the date of the first event => will override default value if set","defaultValue":"firstEventDateTime","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"lastEventDateTime.out.field","isRequired":false,"description":"the name of the field containing the date of the last event => will override default value if set","defaultValue":"lastEventDateTime","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sessionInactivityDuration.out.field","isRequired":false,"description":"the name of the field containing the session inactivity duration => will override default value if set","defaultValue":"sessionInactivityDuration","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"ConvertFieldsType","description":"Converts a field value into the given type. does nothing if conversion is not possible","component":"com.hurence.logisland.processor.ConvertFieldsType","type":"processor","tags":["type","fields","update","convert"],"dynamicProperties":[{"name":"field","value":"the new type","description":"convert field value into new type","isExpressionLanguageSupported":true}]},
{"name":"DebugStream","description":"This is a processor that logs incoming records","component":"com.hurence.logisland.processor.DebugStream","type":"processor","tags":["record","debug"],"properties":[{"name":"event.serializer","isRequired":true,"description":"the way to serialize event","Json serialization":"serialize events as json blocs","String serialization":"serialize events as toString() blocs","defaultValue":"json","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"DetectOutliers","description":"Outlier Analysis: A Hybrid Approach\n\nIn order to function at scale, a two-phase approach is taken\n\nFor every data point\n\n- Detect outlier candidates using a robust estimator of variability (e.g. median absolute deviation) that uses distributional sketching (e.g. Q-trees)\n- Gather a biased sample (biased by recency)\n- Extremely deterministic in space and cheap in computation\n\nFor every outlier candidate\n\n- Use traditional, more computationally complex approaches to outlier analysis (e.g. Robust PCA) on the biased sample\n- Expensive computationally, but run infrequently\n\nThis becomes a data filter which can be attached to a timeseries data stream within a distributed computational framework (i.e. Storm, Spark, Flink, NiFi) to detect outliers.","component":"com.hurence.logisland.processor.DetectOutliers","type":"processor","tags":["analytic","outlier","record","iot","timeseries"],"properties":[{"name":"value.field","isRequired":true,"description":"the numeric field to get the value","defaultValue":"record_value","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"time.field","isRequired":true,"description":"the numeric field to get the value","defaultValue":"record_time","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"output.record.type","isRequired":false,"description":"the output type of the record","defaultValue":"alert_match","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rotation.policy.type","isRequired":true,"description":"...","by_amount":null,"by_time":null,"never":null,"defaultValue":"by_amount","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rotation.policy.amount","isRequired":true,"description":"...","defaultValue":"100","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rotation.policy.unit","isRequired":true,"description":"...","milliseconds":null,"seconds":null,"hours":null,"days":null,"months":null,"years":null,"points":null,"defaultValue":"points","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"chunking.policy.type","isRequired":true,"description":"...","by_amount":null,"by_time":null,"never":null,"defaultValue":"by_amount","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"chunking.policy.amount","isRequired":true,"description":"...","defaultValue":"100","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"chunking.policy.unit","isRequired":true,"description":"...","milliseconds":null,"seconds":null,"hours":null,"days":null,"months":null,"years":null,"points":null,"defaultValue":"points","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sketchy.outlier.algorithm","isRequired":false,"description":"...","SKETCHY_MOVING_MAD":null,"defaultValue":"SKETCHY_MOVING_MAD","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"batch.outlier.algorithm","isRequired":false,"description":"...","RAD":null,"defaultValue":"RAD","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"global.statistics.min","isRequired":false,"description":"minimum value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"global.statistics.max","isRequired":false,"description":"maximum value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"global.statistics.mean","isRequired":false,"description":"mean value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"global.statistics.stddev","isRequired":false,"description":"standard deviation value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"zscore.cutoffs.normal","isRequired":true,"description":"zscoreCutoffs level for normal outlier","defaultValue":"0.000000000000001","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"zscore.cutoffs.moderate","isRequired":true,"description":"zscoreCutoffs level for moderate outlier","defaultValue":"1.5","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"zscore.cutoffs.severe","isRequired":true,"description":"zscoreCutoffs level for severe outlier","defaultValue":"10.0","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"zscore.cutoffs.notEnoughData","isRequired":false,"description":"zscoreCutoffs level for notEnoughData outlier","defaultValue":"100","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"smooth","isRequired":false,"description":"do smoothing ?","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"decay","isRequired":false,"description":"the decay","defaultValue":"0.1","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"min.amount.to.predict","isRequired":true,"description":"minAmountToPredict","defaultValue":"100","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"min_zscore_percentile","isRequired":false,"description":"minZscorePercentile","defaultValue":"50.0","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"reservoir_size","isRequired":false,"description":"the size of points reservoir","defaultValue":"100","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rpca.force.diff","isRequired":false,"description":"No Description Provided.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rpca.lpenalty","isRequired":false,"description":"No Description Provided.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rpca.min.records","isRequired":false,"description":"No Description Provided.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rpca.spenalty","isRequired":false,"description":"No Description Provided.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"rpca.threshold","isRequired":false,"description":"No Description Provided.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"EnrichRecordsElasticsearch","description":"Enrich input records with content indexed in elasticsearch using multiget queries.\nEach incoming record must be possibly enriched with information stored in elasticsearch. \nThe plugin properties are :\n- es.index (String)            : Name of the elasticsearch index on which the multiget query will be performed. This field is mandatory and should not be empty, otherwise an error output record is sent for this specific incoming record.\n- record.key (String)          : Name of the field in the input record containing the id to lookup document in elastic search. This field is mandatory.\n- es.key (String)              : Name of the elasticsearch key on which the multiget query will be performed. This field is mandatory.\n- includes (ArrayList<String>) : List of patterns to filter in (include) fields to retrieve. Supports wildcards. This field is not mandatory.\n- excludes (ArrayList<String>) : List of patterns to filter out (exclude) fields to retrieve. Supports wildcards. This field is not mandatory.\n\nEach outcoming record holds at least the input record plus potentially one or more fields coming from of one elasticsearch document.","component":"com.hurence.logisland.processor.elasticsearch.EnrichRecordsElasticsearch","type":"processor","tags":["elasticsearch"],"properties":[{"name":"elasticsearch.client.service","isRequired":true,"description":"The instance of the Controller Service to use for accessing Elasticsearch.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.key","isRequired":true,"description":"The name of field in the input record containing the document id to use in ES multiget query","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.index","isRequired":true,"description":"The name of the ES index to use in multiget query. ","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.type","isRequired":false,"description":"The name of the ES type to use in multiget query. ","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.includes.field","isRequired":false,"description":"The name of the ES fields to include in the record.","defaultValue":"*","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.excludes.field","isRequired":false,"description":"The name of the ES fields to exclude.","defaultValue":"N/A","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"EvaluateJsonPath","description":"Evaluates one or more JsonPath expressions against the content of a FlowFile. The results of those expressions are assigned to Records Fields depending on configuration of the Processor. JsonPaths are entered by adding user-defined properties; the name of the property maps to the Field Name into which the result will be placed. The value of the property must be a valid JsonPath expression. A Return Type of 'auto-detect' will make a determination based off the configured destination. If the JsonPath evaluates to a JSON array or JSON object and the Return Type is set to 'scalar' the Record will be routed to error. A Return Type of JSON can return scalar values if the provided JsonPath evaluates to the specified value. If the expression matches nothing, Fields will be created with empty strings as the value ","component":"com.hurence.logisland.processor.EvaluateJsonPath","type":"processor","tags":["JSON","evaluate","JsonPath"],"dynamicProperties":[{"name":"A Record field","value":"A JsonPath expression","description":"will be set to any JSON objects that match the JsonPath. ","isExpressionLanguageSupported":false}]},
{"name":"FetchHBaseRow","description":"Fetches a row from an HBase table. The Destination property controls whether the cells are added as flow file attributes, or the row is written to the flow file content as JSON. This processor may be used to fetch a fixed row on a interval by specifying the table and row id directly in the processor, or it may be used to dynamically fetch rows by referencing the table and row id from incoming flow files.","component":"com.hurence.logisland.processor.hbase.FetchHBaseRow","type":"processor","tags":["hbase","scan","fetch","get","enrich"],"properties":[{"name":"hbase.client.service","isRequired":true,"description":"The instance of the Controller Service to use for accessing HBase.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"table.name.field","isRequired":true,"description":"The field containing the name of the HBase Table to fetch from.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"row.identifier.field","isRequired":true,"description":"The field containing the  identifier of the row to fetch.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"columns.field","isRequired":false,"description":"The field containing an optional comma-separated list of \"<colFamily>:<colQualifier>\" pairs to fetch. To return all columns for a given family, leave off the qualifier such as \"<colFamily1>,<colFamily2>\".","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"record.serializer","isRequired":false,"description":"the serializer needed to i/o the record in the HBase row","kryo serialization":"serialize events as json blocs","json serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.schema","isRequired":false,"description":"the avro schema definition for the Avro serialization","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"table.name.default","isRequired":false,"description":"The table table to use if table name field is not set","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"FilterRecords","description":"Keep only records based on a given field value","component":"com.hurence.logisland.processor.FilterRecords","type":"processor","tags":["record","fields","remove","delete"],"properties":[{"name":"field.name","isRequired":true,"description":"the field name","defaultValue":"record_id","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"field.value","isRequired":true,"description":"the field value to keep","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"GenerateRandomRecord","description":"This is a processor that make random records given an Avro schema","component":"com.hurence.logisland.processor.GenerateRandomRecord","type":"processor","tags":["record","avro","generator"],"properties":[{"name":"avro.output.schema","isRequired":true,"description":"the avro schema definition for the output serialization","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"min.events.count","isRequired":true,"description":"the minimum number of generated events each run","defaultValue":"10","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"max.events.count","isRequired":true,"description":"the maximum number of generated events each run","defaultValue":"200","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"KafkaRecordStreamDebugger","description":"No description provided.","component":"com.hurence.logisland.stream.spark.KafkaRecordStreamDebugger","type":"stream","properties":[{"name":"kafka.error.topics","isRequired":true,"description":"Sets the error topics Kafka topic name","defaultValue":"_errors","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics","isRequired":true,"description":"Sets the input Kafka topic name","defaultValue":"_raw","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics","isRequired":true,"description":"Sets the output Kafka topic name","defaultValue":"_records","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metrics.topic","isRequired":false,"description":"a topic to send metrics of processing. no output if not set","defaultValue":"_metrics","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.input.schema","isRequired":false,"description":"the avro schema definition","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.output.schema","isRequired":false,"description":"the avro schema definition for the output serialization","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.error.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.JsonSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.autoCreate","isRequired":false,"description":"define wether a topic should be created automatically if not already exists","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.partitions","isRequired":false,"description":"if autoCreate is set to true, this will set the number of partition at topic creation time","defaultValue":"20","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.replicationFactor","isRequired":false,"description":"if autoCreate is set to true, this will set the number of replica for each partition at topic creation time","defaultValue":"3","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metadata.broker.list","isRequired":true,"description":"a comma separated list of host:port brokers","defaultValue":"sandbox:9092","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.zookeeper.quorum","isRequired":true,"description":"No Description Provided.","defaultValue":"sandbox:2181","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.manual.offset.reset","isRequired":false,"description":"Sets manually an initial offset in ZooKeeper: smallest (automatically reset the offset to the smallest offset), largest (automatically reset the offset to the largest offset), anything else (throw exception to the consumer)","largest offset":"the offset to the largest offset","smallest offset":"the offset to the smallest offset","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.quorum","isRequired":true,"description":"the stream needs to know how to reach Agent REST api in order to live update its processors","defaultValue":"sandbox:8081","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.pull.throttling","isRequired":false,"description":"wait every x batch to pull agent for new conf","defaultValue":"10","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]}{"name":"KafkaRecordStreamHDFSBurner","description":"No description provided.","component":"com.hurence.logisland.stream.spark.KafkaRecordStreamHDFSBurner","type":"stream","properties":[{"name":"kafka.error.topics","isRequired":true,"description":"Sets the error topics Kafka topic name","defaultValue":"_errors","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics","isRequired":true,"description":"Sets the input Kafka topic name","defaultValue":"_raw","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics","isRequired":true,"description":"Sets the output Kafka topic name","defaultValue":"_records","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metrics.topic","isRequired":false,"description":"a topic to send metrics of processing. no output if not set","defaultValue":"_metrics","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.input.schema","isRequired":false,"description":"the avro schema definition","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.output.schema","isRequired":false,"description":"the avro schema definition for the output serialization","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.error.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.JsonSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.autoCreate","isRequired":false,"description":"define wether a topic should be created automatically if not already exists","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.partitions","isRequired":false,"description":"if autoCreate is set to true, this will set the number of partition at topic creation time","defaultValue":"20","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.replicationFactor","isRequired":false,"description":"if autoCreate is set to true, this will set the number of replica for each partition at topic creation time","defaultValue":"3","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metadata.broker.list","isRequired":true,"description":"a comma separated list of host:port brokers","defaultValue":"sandbox:9092","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.zookeeper.quorum","isRequired":true,"description":"No Description Provided.","defaultValue":"sandbox:2181","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.manual.offset.reset","isRequired":false,"description":"Sets manually an initial offset in ZooKeeper: smallest (automatically reset the offset to the smallest offset), largest (automatically reset the offset to the largest offset), anything else (throw exception to the consumer)","largest offset":"the offset to the largest offset","smallest offset":"the offset to the smallest offset","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.quorum","isRequired":true,"description":"the stream needs to know how to reach Agent REST api in order to live update its processors","defaultValue":"sandbox:8081","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.pull.throttling","isRequired":false,"description":"wait every x batch to pull agent for new conf","defaultValue":"10","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"output.folder.path","isRequired":true,"description":"the location where to put files : file:///tmp/out","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"output.format","isRequired":true,"description":"can be parquet, orc csv","parquet":null,"txt":null,"json":null,"json":null,"defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.type","isRequired":true,"description":"the type of event to filter","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"num.partitions","isRequired":false,"description":"the numbers of physical files on HDFS","defaultValue":"4","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"exclude.errors","isRequired":false,"description":"do we include records with errors ?","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]}{"name":"KafkaRecordStreamParallelProcessing","description":"No description provided.","component":"com.hurence.logisland.stream.spark.KafkaRecordStreamParallelProcessing","type":"stream","properties":[{"name":"kafka.error.topics","isRequired":true,"description":"Sets the error topics Kafka topic name","defaultValue":"_errors","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics","isRequired":true,"description":"Sets the input Kafka topic name","defaultValue":"_raw","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics","isRequired":true,"description":"Sets the output Kafka topic name","defaultValue":"_records","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metrics.topic","isRequired":false,"description":"a topic to send metrics of processing. no output if not set","defaultValue":"_metrics","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.input.schema","isRequired":false,"description":"the avro schema definition","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.output.schema","isRequired":false,"description":"the avro schema definition for the output serialization","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.error.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.JsonSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.autoCreate","isRequired":false,"description":"define wether a topic should be created automatically if not already exists","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.partitions","isRequired":false,"description":"if autoCreate is set to true, this will set the number of partition at topic creation time","defaultValue":"20","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.replicationFactor","isRequired":false,"description":"if autoCreate is set to true, this will set the number of replica for each partition at topic creation time","defaultValue":"3","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metadata.broker.list","isRequired":true,"description":"a comma separated list of host:port brokers","defaultValue":"sandbox:9092","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.zookeeper.quorum","isRequired":true,"description":"No Description Provided.","defaultValue":"sandbox:2181","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.manual.offset.reset","isRequired":false,"description":"Sets manually an initial offset in ZooKeeper: smallest (automatically reset the offset to the smallest offset), largest (automatically reset the offset to the largest offset), anything else (throw exception to the consumer)","largest offset":"the offset to the largest offset","smallest offset":"the offset to the smallest offset","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.quorum","isRequired":true,"description":"the stream needs to know how to reach Agent REST api in order to live update its processors","defaultValue":"sandbox:8081","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.pull.throttling","isRequired":false,"description":"wait every x batch to pull agent for new conf","defaultValue":"10","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"max.results.count","isRequired":false,"description":"the max number of rows to output. (-1 for no limit)","defaultValue":"-1","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sql.query","isRequired":true,"description":"The SQL query to execute, please note that the table name must exists in input topics names","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]}{"name":"KafkaRecordStreamSQLAggregator","description":"This is a stream capable of SQL query interpretations","component":"com.hurence.logisland.stream.spark.KafkaRecordStreamSQLAggregator","type":"stream","tags":["stream","SQL","query","record"],"properties":[{"name":"kafka.error.topics","isRequired":true,"description":"Sets the error topics Kafka topic name","defaultValue":"_errors","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics","isRequired":true,"description":"Sets the input Kafka topic name","defaultValue":"_raw","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics","isRequired":true,"description":"Sets the output Kafka topic name","defaultValue":"_records","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metrics.topic","isRequired":false,"description":"a topic to send metrics of processing. no output if not set","defaultValue":"_metrics","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.input.schema","isRequired":false,"description":"the avro schema definition","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"avro.output.schema","isRequired":false,"description":"the avro schema definition for the output serialization","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.input.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.output.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.error.topics.serializer","isRequired":false,"description":"No Description Provided.","kryo serialization":"serialize events as json blocs","avro serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","byte array serialization":"serialize events as byte arrays","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.JsonSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.autoCreate","isRequired":false,"description":"define wether a topic should be created automatically if not already exists","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.partitions","isRequired":false,"description":"if autoCreate is set to true, this will set the number of partition at topic creation time","defaultValue":"20","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.topic.default.replicationFactor","isRequired":false,"description":"if autoCreate is set to true, this will set the number of replica for each partition at topic creation time","defaultValue":"3","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.metadata.broker.list","isRequired":true,"description":"a comma separated list of host:port brokers","defaultValue":"sandbox:9092","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.zookeeper.quorum","isRequired":true,"description":"No Description Provided.","defaultValue":"sandbox:2181","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"kafka.manual.offset.reset","isRequired":false,"description":"Sets manually an initial offset in ZooKeeper: smallest (automatically reset the offset to the smallest offset), largest (automatically reset the offset to the largest offset), anything else (throw exception to the consumer)","largest offset":"the offset to the largest offset","smallest offset":"the offset to the smallest offset","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.quorum","isRequired":true,"description":"the stream needs to know how to reach Agent REST api in order to live update its processors","defaultValue":"sandbox:8081","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.agent.pull.throttling","isRequired":false,"description":"wait every x batch to pull agent for new conf","defaultValue":"10","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"max.results.count","isRequired":false,"description":"the max number of rows to output. (-1 for no limit)","defaultValue":"-1","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sql.query","isRequired":true,"description":"The SQL query to execute, please note that the table name must exists in input topics names","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"output.record.type","isRequired":false,"description":"the output type of the record","defaultValue":"aggregation","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]}{"name":"KafkaStreamProcessingEngine","description":"No description provided.","component":"com.hurence.logisland.engine.spark.KafkaStreamProcessingEngine","type":"engine","properties":[{"name":"spark.app.name","isRequired":true,"description":"Tha application name","defaultValue":"logisland","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.master","isRequired":true,"description":"The url to Spark Master","defaultValue":"local[2]","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.yarn.deploy-mode","isRequired":false,"description":"The yarn deploy mode","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.yarn.queue","isRequired":false,"description":"The name of the YARN queue","defaultValue":"default","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.driver.memory","isRequired":false,"description":"The memory size for Spark driver","defaultValue":"512m","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.executor.memory","isRequired":false,"description":"The memory size for Spark executors","defaultValue":"1g","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.driver.cores","isRequired":false,"description":"The number of cores for Spark driver","defaultValue":"4","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.executor.cores","isRequired":false,"description":"The number of cores for Spark driver","defaultValue":"1","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.executor.instances","isRequired":false,"description":"The number of instances for Spark app","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.serializer","isRequired":false,"description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form","defaultValue":"org.apache.spark.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.blockInterval","isRequired":false,"description":"Interval at which data received by Spark Streaming receivers is chunked into blocks of data before storing them in Spark. Minimum recommended - 50 ms","defaultValue":"350","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.kafka.maxRatePerPartition","isRequired":false,"description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition","defaultValue":"5000","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.batchDuration","isRequired":true,"description":"No Description Provided.","defaultValue":"2000","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.backpressure.enabled","isRequired":false,"description":"This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.unpersist","isRequired":false,"description":"Force RDDs generated and persisted by Spark Streaming to be automatically unpersisted from Spark's memory. The raw input data received by Spark Streaming is also automatically cleared. Setting this to false will allow the raw data and persisted RDDs to be accessible outside the streaming application as they will not be cleared automatically. But it comes at the cost of higher memory usage in Spark.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.ui.port","isRequired":false,"description":"No Description Provided.","defaultValue":"4050","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.timeout","isRequired":false,"description":"No Description Provided.","defaultValue":"-1","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.kafka.maxRetries","isRequired":false,"description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition","defaultValue":"3","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.ui.retainedBatches","isRequired":false,"description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting.","defaultValue":"200","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.streaming.receiver.writeAheadLog.enable","isRequired":false,"description":"Enable write ahead logs for receivers. All the input data received through receivers will be saved to write ahead logs that will allow it to be recovered after driver failures.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.yarn.maxAppAttempts","isRequired":false,"description":"Because Spark driver and Application Master share a single JVM, any error in Spark driver stops our long-running job. Fortunately it is possible to configure maximum number of attempts that will be made to re-run the application. It is reasonable to set higher value than default 2 (derived from YARN cluster property yarn.resourcemanager.am.max-attempts). 4 works quite well, higher value may cause unnecessary restarts even if the reason of the failure is permanent.","defaultValue":"4","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.yarn.am.attemptFailuresValidityInterval","isRequired":false,"description":"If the application runs for days or weeks without restart or redeployment on highly utilized cluster, 4 attempts could be exhausted in few hours. To avoid this situation, the attempt counter should be reset on every hour of so.","defaultValue":"1h","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.yarn.max.executor.failures","isRequired":false,"description":"a maximum number of executor failures before the application fails. By default it is max(2 * num executors, 3), well suited for batch jobs but not for long-running jobs. The property comes with corresponding validity interval which also should be set.8 * num_executors","defaultValue":"20","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.yarn.executor.failuresValidityInterval","isRequired":false,"description":"If the application runs for days or weeks without restart or redeployment on highly utilized cluster, x attempts could be exhausted in few hours. To avoid this situation, the attempt counter should be reset on every hour of so.","defaultValue":"1h","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"spark.task.maxFailures","isRequired":false,"description":"For long-running jobs you could also consider to boost maximum number of task failures before giving up the job. By default tasks will be retried 4 times and then job fails.","defaultValue":"8","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]}{"name":"MatchQuery","description":"Query matching based on `Luwak <http://www.confluent.io/blog/real-time-full-text-search-with-luwak-and-samza/>`_\n\nyou can use this processor to handle custom events defined by lucene queries\na new record is added to output each time a registered query is matched\n\nA query is expressed as a lucene query against a field like for example: \n\n.. code::\n\n\tmessage:'bad exception'\n\terror_count:[10 TO *]\n\tbytes_out:5000\n\tuser_name:tom*\n\nPlease read the `Lucene syntax guide <https://lucene.apache.org/core/5_5_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package_description>`_ for supported operations\n\n.. warning::\n\n\tdon't forget to set numeric fields property to handle correctly numeric ranges queries","component":"com.hurence.logisland.processor.MatchQuery","type":"processor","tags":["analytic","percolator","record","record","query","lucene"],"properties":[{"name":"numeric.fields","isRequired":false,"description":"a comma separated string of numeric field to be matched","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"output.record.type","isRequired":false,"description":"the output type of the record","defaultValue":"alert_match","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"include.input.records","isRequired":false,"description":"if set to true all the input records are copied to output","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}],"dynamicProperties":[{"name":"query","value":"some Lucene query","description":"generate a new record when this query is matched","isExpressionLanguageSupported":true}]},
{"name":"ModifyId","description":"modify id of records or generate it following defined rules","component":"com.hurence.logisland.processor.ModifyId","type":"processor","tags":["record","id","idempotent","generate","modify"],"properties":[{"name":"id.generation.strategy","isRequired":true,"description":"the strategy to generate new Id","generate a random uid":"generate a randomUid using java library","generate a hash from fields":"generate a hash from fields","generate a string from java pattern and fields":"generate a string from java pattern and fields","generate a concatenation of type, time and a hash from fields":"generate a concatenation of type, time and a hash from fields (as for generate_hash strategy)","defaultValue":"randomUuid","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"fields.to.hash","isRequired":true,"description":"the comma separated list of field names (e.g. : 'policyid,date_raw'","defaultValue":"record_raw_value","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"hash.charset","isRequired":true,"description":"the charset to use to hash id string (e.g. 'UTF-8')","defaultValue":"UTF-8","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"hash.algorithm","isRequired":true,"description":"the algorithme to use to hash id string (e.g. 'SHA-256'","SHA-384":null,"SHA-224":null,"SHA-256":null,"MD2":null,"SHA":null,"SHA-512":null,"MD5":null,"defaultValue":"SHA-256","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"java.formatter.string","isRequired":false,"description":"the format to use to build id string (e.g. '%4$2s %3$2s %2$2s %1$2s' (see java Formatter)","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"language.tag","isRequired":true,"description":"the language to use to format numbers in string","aa":null,"ab":null,"ae":null,"af":null,"ak":null,"am":null,"an":null,"ar":null,"as":null,"av":null,"ay":null,"az":null,"ba":null,"be":null,"bg":null,"bh":null,"bi":null,"bm":null,"bn":null,"bo":null,"br":null,"bs":null,"ca":null,"ce":null,"ch":null,"co":null,"cr":null,"cs":null,"cu":null,"cv":null,"cy":null,"da":null,"de":null,"dv":null,"dz":null,"ee":null,"el":null,"en":null,"eo":null,"es":null,"et":null,"eu":null,"fa":null,"ff":null,"fi":null,"fj":null,"fo":null,"fr":null,"fy":null,"ga":null,"gd":null,"gl":null,"gn":null,"gu":null,"gv":null,"ha":null,"he":null,"hi":null,"ho":null,"hr":null,"ht":null,"hu":null,"hy":null,"hz":null,"ia":null,"id":null,"ie":null,"ig":null,"ii":null,"ik":null,"in":null,"io":null,"is":null,"it":null,"iu":null,"iw":null,"ja":null,"ji":null,"jv":null,"ka":null,"kg":null,"ki":null,"kj":null,"kk":null,"kl":null,"km":null,"kn":null,"ko":null,"kr":null,"ks":null,"ku":null,"kv":null,"kw":null,"ky":null,"la":null,"lb":null,"lg":null,"li":null,"ln":null,"lo":null,"lt":null,"lu":null,"lv":null,"mg":null,"mh":null,"mi":null,"mk":null,"ml":null,"mn":null,"mo":null,"mr":null,"ms":null,"mt":null,"my":null,"na":null,"nb":null,"nd":null,"ne":null,"ng":null,"nl":null,"nn":null,"no":null,"nr":null,"nv":null,"ny":null,"oc":null,"oj":null,"om":null,"or":null,"os":null,"pa":null,"pi":null,"pl":null,"ps":null,"pt":null,"qu":null,"rm":null,"rn":null,"ro":null,"ru":null,"rw":null,"sa":null,"sc":null,"sd":null,"se":null,"sg":null,"si":null,"sk":null,"sl":null,"sm":null,"sn":null,"so":null,"sq":null,"sr":null,"ss":null,"st":null,"su":null,"sv":null,"sw":null,"ta":null,"te":null,"tg":null,"th":null,"ti":null,"tk":null,"tl":null,"tn":null,"to":null,"tr":null,"ts":null,"tt":null,"tw":null,"ty":null,"ug":null,"uk":null,"ur":null,"uz":null,"ve":null,"vi":null,"vo":null,"wa":null,"wo":null,"xh":null,"yi":null,"yo":null,"za":null,"zh":null,"zu":null,"defaultValue":"en","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"MultiGetElasticsearch","description":"Retrieves a content indexed in elasticsearch using elasticsearch multiget queries.\nEach incoming record contains information regarding the elasticsearch multiget query that will be performed. This information is stored in record fields whose names are configured in the plugin properties (see below) :\n- index (String) : name of the elasticsearch index on which the multiget query will be performed. This field is mandatory and should not be empty, otherwise an error output record is sent for this specific incoming record.\n- type (String) : name of the elasticsearch type on which the multiget query will be performed. This field is not mandatory.\n- ids (String) : comma separated list of document ids to fetch. This field is mandatory and should not be empty, otherwise an error output record is sent for this specific incoming record.\n- includes (String) : comma separated list of patterns to filter in (include) fields to retrieve. Supports wildcards. This field is not mandatory.\n- excludes (String) : comma separated list of patterns to filter out (exclude) fields to retrieve. Supports wildcards. This field is not mandatory.\n\nEach outcoming record holds data of one elasticsearch retrieved document. This data is stored in these fields :\n- index (same field name as the incoming record) : name of the elasticsearch index.\n- type (same field name as the incoming record) : name of the elasticsearch type.\n- id (same field name as the incoming record) : retrieved document id.\n- a list of String fields containing :\n   * field name : the retrieved field name\n   * field value : the retrieved field value","component":"com.hurence.logisland.processor.elasticsearch.MultiGetElasticsearch","type":"processor","tags":["elasticsearch"],"properties":[{"name":"elasticsearch.client.service","isRequired":true,"description":"The instance of the Controller Service to use for accessing Elasticsearch.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.index.field","isRequired":true,"description":"the name of the incoming records field containing es index name to use in multiget query. ","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.type.field","isRequired":true,"description":"the name of the incoming records field containing es type name to use in multiget query","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.ids.field","isRequired":true,"description":"the name of the incoming records field containing es document Ids to use in multiget query","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.includes.field","isRequired":true,"description":"the name of the incoming records field containing es includes to use in multiget query","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"es.excludes.field","isRequired":true,"description":"the name of the incoming records field containing es excludes to use in multiget query","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"NormalizeFields","description":"Changes the name of a field according to a provided name mapping\n...","component":"com.hurence.logisland.processor.NormalizeFields","type":"processor","tags":["record","fields","normalizer"],"properties":[{"name":"conflict.resolution.policy","isRequired":true,"description":"waht to do when a field with the same name already exists ?","nothing to do":"leave record as it was","overwrite existing field":"if field already exist","keep only old field and delete the other":"keep only old field and delete the other","keep old field and new one":"creates an alias for the new field","defaultValue":"do_nothing","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}],"dynamicProperties":[{"name":"alternative mapping","value":"a comma separated list of possible field name","description":"when a field has a name contained in the list it will be renamed with this property field name","isExpressionLanguageSupported":true}]},
{"name":"ParseBroEvent","description":"The ParseBroEvent processor is the Logisland entry point to get and process `Bro <https://www.bro.org>`_ events. The `Bro-Kafka plugin <https://github.com/bro/bro-plugins/tree/master/kafka>`_ should be used and configured in order to have Bro events sent to Kafka. See the `Bro/Logisland tutorial <http://logisland.readthedocs.io/en/latest/tutorials/indexing-bro-events.html>`_ for an example of usage for this processor. The ParseBroEvent processor does some minor pre-processing on incoming Bro events from the Bro-Kafka plugin to adapt them to Logisland.\n\nBasically the events coming from the Bro-Kafka plugin are JSON documents with a first level field indicating the type of the event. The ParseBroEvent processor takes the incoming JSON document, sets the event type in a record_type field and sets the original sub-fields of the JSON event as first level fields in the record. Also any dot in a field name is transformed into an underscore. Thus, for instance, the field id.orig_h becomes id_orig_h. The next processors in the stream can then process the Bro events generated by this ParseBroEvent processor.\n\nAs an example here is an incoming event from Bro:\n\n{\n\n   \"conn\": {\n\n     \"id.resp_p\": 9092,\n\n     \"resp_pkts\": 0,\n\n     \"resp_ip_bytes\": 0,\n\n     \"local_orig\": true,\n\n     \"orig_ip_bytes\": 0,\n\n     \"orig_pkts\": 0,\n\n     \"missed_bytes\": 0,\n\n     \"history\": \"Cc\",\n\n     \"tunnel_parents\": [],\n\n     \"id.orig_p\": 56762,\n\n     \"local_resp\": true,\n\n     \"uid\": \"Ct3Ms01I3Yc6pmMZx7\",\n\n     \"conn_state\": \"OTH\",\n\n     \"id.orig_h\": \"172.17.0.2\",\n\n     \"proto\": \"tcp\",\n\n     \"id.resp_h\": \"172.17.0.3\",\n\n     \"ts\": 1487596886.953917\n\n   }\n\n }\n\nIt gets processed and transformed into the following Logisland record by the ParseBroEvent processor:\n\n\"@timestamp\": \"2017-02-20T13:36:32Z\"\n\n\"record_id\": \"6361f80a-c5c9-4a16-9045-4bb51736333d\"\n\n\"record_time\": 1487597792782\n\n\"record_type\": \"conn\"\n\n\"id_resp_p\": 9092\n\n\"resp_pkts\": 0\n\n\"resp_ip_bytes\": 0\n\n\"local_orig\": true\n\n\"orig_ip_bytes\": 0\n\n\"orig_pkts\": 0\n\n\"missed_bytes\": 0\n\n\"history\": \"Cc\"\n\n\"tunnel_parents\": []\n\n\"id_orig_p\": 56762\n\n\"local_resp\": true\n\n\"uid\": \"Ct3Ms01I3Yc6pmMZx7\"\n\n\"conn_state\": \"OTH\"\n\n\"id_orig_h\": \"172.17.0.2\"\n\n\"proto\": \"tcp\"\n\n\"id_resp_h\": \"172.17.0.3\"\n\n\"ts\": 1487596886.953917","component":"com.hurence.logisland.processor.bro.ParseBroEvent","type":"processor","tags":["bro","security","IDS","NIDS"],"properties":[{"name":"debug","isRequired":false,"description":"Enable debug. If enabled, the original JSON string is embedded in the record_value field of the record.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"ParseNetflowEvent","description":"The `Netflow V5 <http://www.cisco.com/c/en/us/td/docs/ios/solutions_docs/netflow/nfwhite.html>`_ processor is the Logisland entry point to  process Netflow (V5) events. NetFlow is a feature introduced on Cisco routers that provides the ability to collect IP network traffic.We can distinguish 2 components:\n\n\t-Flow exporter: aggregates packets into flows and exports flow records (binary format) towards one or more flow collectors\n\n\t-Flow collector: responsible for reception, storage and pre-processing of flow data received from a flow exporter\nThe collected data are then available for analysis purpose (intrusion detection, traffic analysis...)\nNetflow are sent to kafka in order to be processed by logisland.\nIn the tutorial we will simulate Netflow traffic using `nfgen <https://github.com/pazdera/NetFlow-Exporter-Simulator>`_. this traffic will be sent to port 2055. The we rely on nifi to listen of that port for   incoming netflow (V5) traffic and send them to a kafka topic. The Netflow processor could thus treat these events and generate corresponding logisland records. The following processors in the stream can then process the Netflow records generated by this processor.","component":"com.hurence.logisland.processor.netflow.ParseNetflowEvent","type":"processor","tags":["netflow","security"],"properties":[{"name":"debug","isRequired":false,"description":"Enable debug. If enabled, the original JSON string is embedded in the record_value field of the record.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"output.record.type","isRequired":false,"description":"the output type of the record","defaultValue":"netflowevent","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"enrich.record","isRequired":false,"description":"Enrich data. If enabledthe netflow record is enriched with inferred data","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"ParseNetworkPacket","description":"The ParseNetworkPacket processor is the LogIsland entry point to parse network packets captured either off-the-wire (stream mode) or in pcap format (batch mode).  In batch mode, the processor decodes the bytes of the incoming pcap record, where a Global header followed by a sequence of [packet header, packet data] pairs are stored. Then, each incoming pcap event is parsed into n packet records. The fields of packet headers are then extracted and made available in dedicated record fields. See the `Capturing Network packets tutorial <http://logisland.readthedocs.io/en/latest/tutorials/indexing-network-packets.html>`_ for an example of usage of this processor.","component":"com.hurence.logisland.processor.networkpacket.ParseNetworkPacket","type":"processor","tags":["PCap","security","IDS","NIDS"],"properties":[{"name":"debug","isRequired":false,"description":"Enable debug.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"flow.mode","isRequired":true,"description":"Flow Mode. Indicate whether packets are provided in batch mode (via pcap files) or in stream mode (without headers). Allowed values are batch and stream.","batch":null,"stream":null,"defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"ParseProperties","description":"Parse a field made of key=value fields separated by spaces\na string like \"a=1 b=2 c=3\" will add a,b & c fields, respectively with values 1,2 & 3 to the current Record","component":"com.hurence.logisland.processor.ParseProperties","type":"processor","tags":["record","properties","parser"],"properties":[{"name":"properties.field","isRequired":true,"description":"the field containing the properties to split and treat","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"ParseUserAgent","description":"The user-agent processor allows to decompose User-Agent value from an HTTP header into several attributes of interest. There is no standard format for User-Agent strings, hence it is not easily possible to use regexp to handle them. This processor rely on the `YAUAA library <https://github.com/nielsbasjes/yauaa>`_ to do the heavy work.","component":"com.hurence.logisland.processor.useragent.ParseUserAgent","type":"processor","tags":["User-Agent","clickstream","DMP"],"properties":[{"name":"debug","isRequired":false,"description":"Enable debug.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"cache.enabled","isRequired":false,"description":"Enable caching. Caching to avoid to redo the same computation for many identical User-Agent strings.","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"cache.size","isRequired":false,"description":"Set the size of the cache.","defaultValue":"1000","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"useragent.field","isRequired":true,"description":"Must contain the name of the field that contains the User-Agent value in the incoming record.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"useragent.keep","isRequired":false,"description":"Defines if the field that contained the User-Agent must be kept or not in the resulting records.","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"confidence.enabled","isRequired":false,"description":"Enable confidence reporting. Each field will report a confidence attribute with a value comprised between 0 and 10000.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"ambiguity.enabled","isRequired":false,"description":"Enable ambiguity reporting. Reports a count of ambiguities.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"fields","isRequired":false,"description":"Defines the fields to be returned.","defaultValue":"DeviceClass, DeviceName, DeviceBrand, DeviceCpu, DeviceFirmwareVersion, DeviceVersion, OperatingSystemClass, OperatingSystemName, OperatingSystemVersion, OperatingSystemNameVersion, OperatingSystemVersionBuild, LayoutEngineClass, LayoutEngineName, LayoutEngineVersion, LayoutEngineVersionMajor, LayoutEngineNameVersion, LayoutEngineNameVersionMajor, LayoutEngineBuild, AgentClass, AgentName, AgentVersion, AgentVersionMajor, AgentNameVersion, AgentNameVersionMajor, AgentBuild, AgentLanguage, AgentLanguageCode, AgentInformationEmail, AgentInformationUrl, AgentSecurity, AgentUuid, FacebookCarrier, FacebookDeviceClass, FacebookDeviceName, FacebookDeviceVersion, FacebookFBOP, FacebookFBSS, FacebookOperatingSystemName, FacebookOperatingSystemVersion, Anonymized, HackerAttackVector, HackerToolkit, KoboAffiliate, KoboPlatformId, IECompatibilityVersion, IECompatibilityVersionMajor, IECompatibilityNameVersion, IECompatibilityNameVersionMajor, __SyntaxError__, Carrier, GSAInstallationID, WebviewAppName, WebviewAppNameVersionMajor, WebviewAppVersion, WebviewAppVersionMajor","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"PutHBaseCell","description":"Adds the Contents of a Record to HBase as the value of a single cell","component":"com.hurence.logisland.processor.hbase.PutHBaseCell","type":"processor","tags":["hadoop","hbase"],"properties":[{"name":"hbase.client.service","isRequired":true,"description":"The instance of the Controller Service to use for accessing HBase.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"table.name.field","isRequired":true,"description":"The field containing the name of the HBase Table to put data into","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"row.identifier.field","isRequired":false,"description":"Specifies  field containing the Row ID to use when inserting data into HBase","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"row.identifier.encoding.strategy","isRequired":false,"description":"Specifies the data type of Row ID used when inserting data into HBase. The default behavior is to convert the row id to a UTF-8 byte array. Choosing Binary will convert a binary formatted string to the correct byte[] representation. The Binary option should be used if you are using Binary row keys in HBase","String":"Stores the value of row id as a UTF-8 String.","Binary":"Stores the value of the rows id as a binary byte array. It expects that the row id is a binary formatted string.","defaultValue":"String","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"column.family.field","isRequired":true,"description":"The field containing the  Column Family to use when inserting data into HBase","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"column.qualifier.field","isRequired":true,"description":"The field containing the  Column Qualifier to use when inserting data into HBase","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":true},{"name":"batch.size","isRequired":true,"description":"The maximum number of Records to process in a single execution. The Records will be grouped by table, and a single Put per table will be performed.","defaultValue":"25","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.schema","isRequired":false,"description":"the avro schema definition for the Avro serialization","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.serializer","isRequired":false,"description":"the serializer needed to i/o the record in the HBase row","kryo serialization":"serialize events as json blocs","json serialization":"serialize events as json blocs","avro serialization":"serialize events as avro blocs","no serialization":"send events as bytes","defaultValue":"com.hurence.logisland.serializer.KryoSerializer","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"table.name.default","isRequired":false,"description":"The table table to use if table name field is not set","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"column.family.default","isRequired":false,"description":"The column family to use if column family field is not set","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"column.qualifier.default","isRequired":false,"description":"The column qualifier to use if column qualifier field is not set","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"RemoveFields","description":"Removes a list of fields defined by a comma separated list of field names","component":"com.hurence.logisland.processor.RemoveFields","type":"processor","tags":["record","fields","remove","delete"],"properties":[{"name":"fields.to.remove","isRequired":true,"description":"the comma separated list of field names (e.g. 'policyid,date_raw'","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"RunPython","description":" !!!! WARNING !!!!\n\nThe RunPython processor is currently an experimental feature : it is delivered as is, with the current set of features and is subject to modifications in API or anything else in further logisland releases without warnings. There is no tutorial yet. If you want to play with this processor, use the python-processing.yml example and send the apache logs of the index apache logs tutorial. The debug stream processor at the end of the stream should output events in stderr file of the executors from the spark console.\n\nThis processor allows to implement and run a processor written in python. This can be done in 2 ways. Either directly defining the process method code in the **script.code.process** configuration property or poiting to an external python module script file in the **script.path** configuration property. Directly defining methods is called the inline mode whereas using a script file is called the file mode. Both ways are mutually exclusive. Whether using the inline of file mode, your python code may depend on some python dependencies. If the set of python dependencies already delivered with the Logisland framework is not sufficient, you can use the **dependencies.path** configuration property to give their location. Currently only the nltk python library is delivered with Logisland.","component":"com.hurence.logisland.processor.scripting.python.RunPython","type":"processor","tags":["scripting","python"],"properties":[{"name":"script.code.imports","isRequired":false,"description":"For inline mode only. This is the pyhton code that should hold the import statements if required.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"script.code.init","isRequired":false,"description":"The python code to be called when the processor is initialized. This is the python equivalent of the init method code for a java processor. This is not mandatory but can only be used if **script.code.process** is defined (inline mode).","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"script.code.process","isRequired":false,"description":"The python code to be called to process the records. This is the pyhton equivalent of the process method code for a java processor. For inline mode, this is the only minimum required configuration property. Using this property, you may also optionally define the **script.code.init** and **script.code.imports** properties.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"script.path","isRequired":false,"description":"The path to the user's python processor script. Use this property for file mode. Your python code must be in a python file with the following constraints: let's say your pyhton script is named MyProcessor.py. Then MyProcessor.py is a module file that must contain a class named MyProcessor which must inherits from the Logisland delivered class named AbstractProcessor. You can then define your code in the process method and in the other traditional methods (init...) as you would do in java in a class inheriting from the AbstractProcessor java class.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"dependencies.path","isRequired":false,"description":"The path to the additional dependencies for the user's python code, whether using inline or file mode. This is optional as your code may not have additional dependencies. If you defined **script.path** (so using file mode) and if **dependencies.path** is not defined, Logisland will scan a potential directory named **dependencies** in the same directory where the script file resides and if it exists, any python code located there will be loaded as dependency as needed.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"logisland.dependencies.path","isRequired":false,"description":"The path to the directory containing the python dependencies shipped with logisland. You should not have to tune this parameter.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"SampleRecords","description":"Query matching based on `Luwak <http://www.confluent.io/blog/real-time-full-text-search-with-luwak-and-samza/>`_\n\nyou can use this processor to handle custom events defined by lucene queries\na new record is added to output each time a registered query is matched\n\nA query is expressed as a lucene query against a field like for example: \n\n.. code::\n\n   message:'bad exception'\n   error_count:[10 TO *]\n   bytes_out:5000\n   user_name:tom*\n\nPlease read the `Lucene syntax guide <https://lucene.apache.org/core/5_5_0/queryparser/org/apache/lucene/queryparser/classic/package-summary.html#package_description>`_ for supported operations\n\n.. warning::\n   don't forget to set numeric fields property to handle correctly numeric ranges queries","component":"com.hurence.logisland.processor.SampleRecords","type":"processor","tags":["analytic","sampler","record","iot","timeseries"],"properties":[{"name":"record.value.field","isRequired":false,"description":"the name of the numeric field to sample","defaultValue":"record_value","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.time.field","isRequired":false,"description":"the name of the time field to sample","defaultValue":"record_time","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sampling.algorithm","isRequired":true,"description":"the implementation of the algorithm","none":null,"lttb":null,"average":null,"first_item":null,"min_max":null,"mode_median":null,"defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"sampling.parameter","isRequired":true,"description":"the parmater of the algorithm","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"SelectDistinctRecords","description":"Keep only distinct records based on a given field","component":"com.hurence.logisland.processor.SelectDistinctRecords","type":"processor","tags":["record","fields","remove","delete"],"properties":[{"name":"field.name","isRequired":true,"description":"the field to distinct records","defaultValue":"record_id","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"SendMail","description":"The SendMail processor is aimed at sending an email (like for instance an alert email) from an incoming record. There are three ways an incoming record can generate an email according to the special fields it must embed. Here is a list of the record fields that generate a mail and how they work:\n\n- **mail_text**: this is the simplest way for generating a mail. If present, this field means to use its content (value) as the payload of the mail to send. The mail is sent in text format if there is only this special field in the record. Otherwise, used with either mail_html or mail_use_template, the content of mail_text is the aletrnative text to the HTML mail that is generated.\n\n- **mail_html**: this field specifies that the mail should be sent as HTML and the value of the field is mail payload. If mail_text is also present, its value is used as the alternative text for the mail. mail_html cannot be used with mail_use_template: only one of those two fields should be present in the record.\n\n- **mail_use_template**: If present, this field specifies that the mail should be sent as HTML and the HTML content is to be generated from the template in the processor configuration key **html.template**. The template can contain parameters which must also be present in the record as fields. See documentation of html.template for further explanations. mail_use_template cannot be used with mail_html: only one of those two fields should be present in the record.\n\n If **allow_overwrite** configuration key is true, any mail.* (dot format) configuration key may be overwritten with a matching field in the record of the form mail_* (underscore format). For instance if allow_overwrite is true and mail.to is set to config_address@domain.com, a record generating a mail with a mail_to field set to record_address@domain.com will send a mail to record_address@domain.com.\n\n Apart from error records (when he is unable to process the incoming record or to send the mail), this processor is not expected to produce any output records.","component":"com.hurence.logisland.processor.SendMail","type":"processor","tags":["smtp","email","e-mail","mail","mailer","sendmail","message","alert","html"],"properties":[{"name":"debug","isRequired":false,"description":"Enable debug. If enabled, debug information are written to stdout.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"smtp.server","isRequired":true,"description":"FQDN, hostname or IP address of the SMTP server to use.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"smtp.port","isRequired":false,"description":"TCP port number of the SMTP server to use.","defaultValue":"25","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"smtp.security.username","isRequired":false,"description":"SMTP username.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"smtp.security.password","isRequired":false,"description":"SMTP password.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"smtp.security.ssl","isRequired":false,"description":"Use SSL under SMTP or not (SMTPS). Default is false.","defaultValue":"false","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"mail.from.address","isRequired":true,"description":"Valid mail sender email address.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"mail.from.name","isRequired":false,"description":"Mail sender name.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"mail.bounce.address","isRequired":true,"description":"Valid bounce email address (where error mail is sent if the mail is refused by the recipient server).","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"mail.replyto.address","isRequired":false,"description":"Reply to email address.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"mail.subject","isRequired":false,"description":"Mail subject.","defaultValue":"[LOGISLAND] Automatic email","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"mail.to","isRequired":false,"description":"Comma separated list of email recipients. If not set, the record must have a mail_to field and allow_overwrite configuration key should be true.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"allow_overwrite","isRequired":false,"description":"If true, allows to overwrite processor configuration with special record fields (mail_to, mail_from_address, mail_from_name, mail_bounce_address, mail_replyto_address, mail_subject). If false, special record fields are ignored and only processor configuration keys are used.","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"html.template","isRequired":false,"description":"HTML template to use. It is used when the incoming record contains a mail_use_template field. The template may contain some parameters. The parameter format in the template is of the form ${xxx}. For instance ${param_user} in the template means that a field named param_user must be present in the record and its value will replace the ${param_user} string in the HTML template when the mail will be sent. If some parameters are declared in the template, everyone of them must be present in the record as fields, otherwise the record will generate an error record. If an incoming record contains a mail_use_template field, a template must be present in the configuration and the HTML mail format will be used. If the record also contains a mail_text field, its content will be used as an alternative text message to be used in the mail reader program of the recipient if it does not supports HTML.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"SplitText","description":"This is a processor that is used to split a String into fields according to a given Record mapping","component":"com.hurence.logisland.processor.SplitText","type":"processor","tags":["parser","regex","log","record"],"properties":[{"name":"value.regex","isRequired":true,"description":"the regex to match for the message value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"value.fields","isRequired":true,"description":"a comma separated list of fields corresponding to matching groups for the message value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"key.regex","isRequired":false,"description":"the regex to match for the message key","defaultValue":".*","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"key.fields","isRequired":false,"description":"a comma separated list of fields corresponding to matching groups for the message key","defaultValue":"record_raw_key","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.type","isRequired":false,"description":"default type of record","defaultValue":"record","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"keep.raw.content","isRequired":false,"description":"do we add the initial raw content ?","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"timezone.record.time","isRequired":false,"description":"what is the time zone of the string formatted date for 'record_time' field.","defaultValue":"UTC","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}],"dynamicProperties":[{"name":"alternative regex & mapping","value":"another regex that could match","description":"this regex will be tried if the main one has not matched. It must be in the form alt.value.regex.1 and alt.value.fields.1","isExpressionLanguageSupported":true}]},
{"name":"SplitTextMultiline","description":"No description provided.","component":"com.hurence.logisland.processor.SplitTextMultiline","type":"processor","properties":[{"name":"regex","isRequired":true,"description":"the regex to match","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"fields","isRequired":true,"description":"a comma separated list of fields corresponding to matching groups","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"event.type","isRequired":true,"description":"the type of event","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"SplitTextWithProperties","description":"This is a processor that is used to split a String into fields according to a given Record mapping","component":"com.hurence.logisland.processor.SplitTextWithProperties","type":"processor","tags":["parser","regex","log","record"],"properties":[{"name":"value.regex","isRequired":true,"description":"the regex to match for the message value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"value.fields","isRequired":true,"description":"a comma separated list of fields corresponding to matching groups for the message value","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"key.regex","isRequired":false,"description":"the regex to match for the message key","defaultValue":".*","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"key.fields","isRequired":false,"description":"a comma separated list of fields corresponding to matching groups for the message key","defaultValue":"record_raw_key","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"record.type","isRequired":false,"description":"default type of record","defaultValue":"record","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"keep.raw.content","isRequired":false,"description":"do we add the initial raw content ?","defaultValue":"true","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"properties.field","isRequired":true,"description":"the field containing the properties to split and treat","defaultValue":"properties","isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}],"dynamicProperties":[{"name":"alternative regex & mapping","value":"another regex that could match","description":"this regex will be tried if the main one has not matched. It must be in the form alt.value.regex.1 and alt.value.fields.1","isExpressionLanguageSupported":true}]},
{"name":"TagBinetflow","description":"No description provided.","component":"com.hurence.logisland.processor.binetflow.TagBinetflow","type":"processor","properties":[{"name":"ml.model.client.service","isRequired":true,"description":"The instance of the Controller Service to use for accessing Machine Learning model.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"ml.scaler.client.service","isRequired":true,"description":"The instance of the Controller Service to use for accessing Machine Learning scaler model.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
{"name":"runDeepLearning","description":"The ml processor has been written to describe how to implement machine Learning Capabilities to logisland. It relies on deeplearning4j libraries to load the model and to run the Neural Network prediction","component":"com.hurence.logisland.processor.ml.runDeepLearning","type":"processor","tags":["machine learning","deep learning"],"properties":[{"name":"debug","isRequired":false,"description":"Enable debug.","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false},{"name":"ml.model.file.path","isRequired":true,"description":"the path of the ml model","defaultValue":null,"isDynamic":false,"isSensitive":false,"isExpressionLanguageSupported":false}]},
]
